{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indmat prosjekt\n",
    "###### Liva Berge Flo, André Pettersen-Dahl, Herman Neple\n",
    "\n",
    "#### Oppgave 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser på et eksempel på et datasett som kan trene en transformermodell som forsøker å predikere et heltall $d$, hvor $d = a \\cdot b + c$. Her er $a$ og $c$ tosifrede heltall og $b$ er et ettsifret heltall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "    \\text{La } r &= 2,   a = 28,  \n",
    " b = 4,   c = 18,   d = 130, \\\\\n",
    "    \\text{da har vi } x &= [2,8,4,1,8,1,3], y = [1,3,0], \\\\\n",
    "    \\text{modellen gir oss } \\hat{z} &= [\\hat{z}_0, \\ldots, \\hat{z}_6] = f_{\\theta}([2,8,4,1,8,1,3]), \\\\\n",
    "    \\text{vi ønsker å finne $\\theta$ slik at } \\hat{y} &= [\\hat{z}_{4}, \\hat{z}_{5}, \\hat{z}_{6}] = [1,3,0].\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ser videre på et eksempel på hvordan transformermodellen $f_{\\theta}$ kan predikere tallet $d$ for samme type problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\\begin{align*}\n",
    "    \\text{La } r &= 2, a = 18, b = 3, c = 22 \\\\\n",
    "    \\text{da har vi } x^{(0)} &= [1,8,3,2,2], & [\\hat{z}_{0}^{(0)},\\hat{z}_{1}^{(0)},\\hat{z}_{2}^{(0)},\\hat{z}_{3}^{(0)},\\hat{z}_{4}^{(0)},\\textcolor{red}{\\hat{z}_{5}^{(0)}}] = f_\\theta(x^{(0)}), \\\\\n",
    "    x^{(1)} &= [1,8,3,2,2,\\textcolor{red}{\\hat{z}_{5}^{(0)}}], & [\\hat{z}_{0}^{(1)},\\ldots, \\textcolor{blue}{\\hat{z}_{6}^{(1)}}] = f_\\theta(x^{(1)}), \\\\ \n",
    "    x^{(2)} &= [1,8,3,2,2,\\textcolor{red}{\\hat{z}_{5}^{(0)}},\\textcolor{blue}{\\hat{z}_{6}^{(1)}}], & [\\hat{z}_{0}^{(1)},\\ldots, \\textcolor{gold}{\\hat{z}_{7}^{(2)}}] = f_\\theta(x^{(2)}), \\\\\n",
    "    x^{(3)} &= [1,8,3,2,2,\\textcolor{red}{\\hat{z}_{5}^{(0)}},\\textcolor{blue}{\\hat{z}_{6}^{(1)}},\\textcolor{gold}{\\hat{z}_{7}^{(2)}}] \\\\\n",
    "    \\hat{y} &= [\\textcolor{red}{\\hat{z}_{5}^{(0)}},\\textcolor{blue}{\\hat{z}_{6}^{(1)}},\\textcolor{gold}{\\hat{z}_{7}^{(2)}}]. \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siden transformermodellen beregner siste siffer i et addisjonsproblem først, vil tallet $d = \\textcolor{gold}{\\hat{z}_{7}^{(2)}}\\textcolor{blue}{\\hat{z}_{6}^{(1)}}\\textcolor{red}{\\hat{z}_{5}^{(0)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La $m = 5$ og $y = [4,3,2,1]$. Vi bruker cross-entropy som objektfunksjon $\\mathcal{L}$, og ønsker å finne en sannsynlighetsfordeling $\\hat Y$ som gir $\\mathcal{L}(\\theta, \\mathcal{D}) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi får altså at \n",
    "\n",
    "$$Y = \\left[\n",
    "\\begin{array}{cccc}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 \n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "når vi representerer $y$ som en matrise, ved å benytte onehot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-entropy vil i vårt tilfelle se slik ut:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, \\mathcal{D}) &= -\\frac{1}{4} \\sum_{i=0}^{0} \\sum_{j=0}^{4} \\log Y_{kj}^{(i)}\n",
    "\\end{align*}\n",
    "\n",
    "hvor vi kun summerer opp til $D = 0$, siden vi kun har ett datasett og summerer opp til $n = 4$, fordi vi har fire elementer i $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siden vi ønsker at $\\mathcal{L}(\\theta, \\mathcal{D}) = 0$, vil vi at alle $Y_{kj}^{(i)} = 1$, slik at logaritmen blir 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$$\\hat Y = \\left[\n",
    "\\begin{array}{cccc}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 \n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "Altså, kan vi observere at:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "Y_{4,0} &= 1 \\\\\n",
    "Y_{3,1} &= 1 \\\\\n",
    "Y_{2,2} &= 1 \\\\\n",
    "Y_{1,3} &= 1 \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Resten av elementene i $Y$ er null. Dermed kan vi forenkle uttrykket for kryssentropien:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, \\mathcal{D}) &= -\\frac{1}{4} \\left( \\log Y_{4,0} + \\log Y_{3,1} + \\log Y_{2,2} + \\log Y_{1,3} \\right) \\\\\n",
    "&= -\\frac{1}{4} \\left( \\log 1 + \\log 1 + \\log 1 + \\log 1 \\right) \\\\\n",
    "&= -\\frac{1}{4} \\cdot 4 \\cdot \\log 1 \\\\\n",
    "&= -\\frac{4}{4} \\cdot 0 \\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Så vi ser at $ \\mathcal{L}(\\theta, \\mathcal{D}) = 0 $, som forventet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi må i dette tilfellet ha at $\\hat y = y$. Dette kan man se dersom man utfører operasjonen $\\text{argmax}_{\\text{col}}(\\hat Y)$. Det kan også observeres at $\\hat Y = Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan begynne med å se på settet av parametere\n",
    "\\begin{align*}\n",
    "\\theta = \\{ W_E, W_P, W_U, \\{W_O^{(l)}, W_V^{(l)}, W_Q^{(l)}, W_K^{(l)}, W_1^{(l)}, W_2^{(l)}\\}_{l=0}^{L-1} \\}\n",
    "\\end{align*}\n",
    "Antall parametere blir da\n",
    "\n",
    "\\begin{align*}\n",
    "n_{w} &=  d \\cdot m + d \\cdot n_{\\text{max}} + d \\cdot m + L\\cdot \\{ 4 ( k \\cdot d ) + 2 (p\\cdot d)\\} \\\\\n",
    "&= 2(d\\cdot m) + d\\cdot n_{\\text{max}} + L\\cdot \\{ 4 ( k \\cdot d ) + 2 (p\\cdot d)\\}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi starte med å gå manuelt gjennom hele transformeralgoritmen med de gitte verdiene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "x &= [1], \\text{       } m = 2 \\\\\n",
    "X &= \\text{onehot}(x) = \n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "1 \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "W_{E} &= \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & \\alpha \\\\\n",
    "\\end{bmatrix}\n",
    "W_{P} = \\begin{bmatrix}\n",
    "    1  \\\\\n",
    "    0  \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "z_{0} &= \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & \\alpha \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}\n",
    "+ \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    0 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "z_{\\frac{1}{2}} &= z_0 + W_{O}^{T}W_{V}z_{0}A(z_{0})\\\\ &= z_{0} + W_{O}^{T}W_{V}z_{0}\\text{ softmax}_{\\text{col }}(z_{0}^{T}W_{Q}^{T}W_{K}z_{0} + D) \\\\\n",
    "&= \\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    1 \\\\\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1 \\\\\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    1 & 1 \\\\\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix} \\text{softmax}_{\\text{col } }(\\begin{bmatrix}\n",
    "    1 & \\alpha\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1 \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1 \\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix} + 0) \\\\\n",
    "&= \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}+\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}\\text{softmax}_{\\text{col }}(1+\\alpha^2) \\\\\n",
    "&= 2 \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "z_1 &= z_{\\frac{1}{2}} + W_{2}^{T}\\sigma(W_1 z_{\\frac{1}{2}})\\\\\n",
    "&= 2_{\\frac{1}{2}} + W_{2}^{T}\\text{max}(0,W_1 z_{\\frac{1}{2}})\\\\\n",
    "&= 2\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}+\\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1 \\\\\n",
    "\\end{bmatrix}\\text{max}\\Bigg(0, \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1 \\\\\n",
    "\\end{bmatrix}2\\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}\\Bigg)\\\\\n",
    "&= 4\\begin{bmatrix}\n",
    "    1\\\\\n",
    "    \\alpha \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align*}\n",
    "Z &= \\text{softmax}_{\\text{col}}(W_{U}^{T}z_{1})\\\\\n",
    "&= \\text{softmax}_{\\text{col}}\\bigg(4\\begin{bmatrix}\n",
    "        1 \\\\\n",
    "        \\alpha \\\\\n",
    "    \\end{bmatrix}\\bigg)\\\\\n",
    "    &= \\begin{bmatrix}\n",
    "        \\frac{e^{4}}{e^{4}+e^{4\\alpha}} \\\\\n",
    "        \\frac{e^{4\\alpha}}{e^{4}+e^{4\\alpha}} \\\\\n",
    "    \\end{bmatrix}\n",
    "    = \\frac{1}{e^{4}+e^{4\\alpha}}\\begin{bmatrix}\n",
    "        e^{4} \\\\\n",
    "        e^{4\\alpha} \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Det kan observeres at $\\text{argmax}_{\\text{col}}$ vil returnere $\\hat{z} = [1]$ dersom $Z_{10}$ er størst. \n",
    "\\begin{align*}\n",
    "e^{4\\alpha} > e^{4} \\implies \\alpha > 1\\\\\n",
    "\\Box\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oppgave 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oppgave 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import *\n",
    "from neural_network import NeuralNetwork\n",
    "from utils import onehot\n",
    "import numpy as np\n",
    "from data_generators import get_train_test_sorting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For å teste om lagene vi har implementert fungerer, kan vi manuelt kjøre gjennom algoritmen. Vi starter med å initalisere lagene til det nevrale nettverk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definerer variabler\n",
    "r = 4\n",
    "m = 4\n",
    "\n",
    "d = 10\n",
    "k = 5\n",
    "p = 15\n",
    "L = 2\n",
    "\n",
    "embed = EmbedPosition(9,m,d)\n",
    "att1 = Attention(d,k)\n",
    "ff1 = FeedForward(d,p)\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan videre gi nettverket vårt en input, la oss f.eks late som vi prøver å få modellen til å sortere tallene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[0,1,2]])\n",
    "X = onehot(x, m)\n",
    "\n",
    "z0 = embed.forward(X)\n",
    "z11 = att1.forward(z0)\n",
    "z12 = ff1.forward(z11)\n",
    "z2 = un_embed.forward(z12)\n",
    "Z = softmax.forward(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan så teste om vi fikk riktig output, som i dette tilfelle burde være at det er $0$ på siste element. Om vi har riktig output skulle loss funksjonen vårt bli 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2937222849497745\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[0]])\n",
    "L = loss.forward(Z,y)\n",
    "\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dette fungerte åpenbart ikke enda. Etter å ha kjørt en forward pass, er det fint å teste backwardfunksjonen til lagene. Vi starter da med å beregne den deriverte av loss funksjonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dLdz = loss.backward()\n",
    "d0 = softmax.backward(dLdz)\n",
    "d1 = un_embed.backward(d0)\n",
    "d21 = ff1.backward(d1)\n",
    "d22 = att1.backward(d21)\n",
    "d3 = embed.backward(d22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oppgave 3.2\n",
    "\n",
    "Vi lager en generell funksjon som vil trene nettverket vårt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Adam(nn: NeuralNetwork, x_data, y_data, n_iters, step_size, m):\n",
    "    n_batches = x_data.shape[0]\n",
    "    mean_losses = np.zeros(n_iters)\n",
    "    for j in range(n_iters):\n",
    "        losses = []\n",
    "        for i in range(n_batches):\n",
    "            x = x_data[i]\n",
    "            y = y_data[i]\n",
    "\n",
    "            X = onehot(x,m)\n",
    "            Z = nn.forward(X)\n",
    "\n",
    "            losses.append(loss.forward(Z,y))\n",
    "            dLdZ = loss.backward()\n",
    "            nn.backward(dLdZ)\n",
    "            nn.step_Adam(step_size)\n",
    "        mean_loss = np.mean(losses)\n",
    "        print(\"Iterasjon \", str(j+1), \" L = \",mean_loss, \"\")\n",
    "        mean_losses[j] = mean_loss\n",
    "    return mean_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Oppgave 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For oppgaven med sortering av 0 og 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definerer variabler\n",
    "r = 5\n",
    "m = 2\n",
    "\n",
    "d = 10\n",
    "k = 5\n",
    "p = 15\n",
    "L = 2\n",
    "\n",
    "embed = EmbedPosition(9,m,d)\n",
    "att1 = Attention(d,k)\n",
    "att2 = Attention(d,k)\n",
    "ff1 = FeedForward(d,p)\n",
    "ff2 = FeedForward(d,p)\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "nn = NeuralNetwork([embed, att1, ff1, att2, ff2, un_embed, softmax])\n",
    "\n",
    "data = get_train_test_sorting(r, m, samples_per_batch=250,n_batches_train=20, n_batches_test=4)\n",
    "\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La oss prøve å trene!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasjon  1  L =  0.6931641505034989 \n",
      "Iterasjon  2  L =  0.691723419576219 \n",
      "Iterasjon  3  L =  0.6902274289959592 \n",
      "Iterasjon  4  L =  0.688677627916117 \n",
      "Iterasjon  5  L =  0.68705137136295 \n",
      "Iterasjon  6  L =  0.6853231893501824 \n",
      "Iterasjon  7  L =  0.6834646137612217 \n",
      "Iterasjon  8  L =  0.6814718119565508 \n",
      "Iterasjon  9  L =  0.6793370942030122 \n",
      "Iterasjon  10  L =  0.6770189666885479 \n",
      "Iterasjon  11  L =  0.6744917814295235 \n",
      "Iterasjon  12  L =  0.6717345581590697 \n",
      "Iterasjon  13  L =  0.668754043277402 \n",
      "Iterasjon  14  L =  0.6655151187064542 \n",
      "Iterasjon  15  L =  0.6619849766168645 \n",
      "Iterasjon  16  L =  0.6581310354812699 \n",
      "Iterasjon  17  L =  0.6539142077362597 \n",
      "Iterasjon  18  L =  0.649337144517841 \n",
      "Iterasjon  19  L =  0.6444095245169398 \n",
      "Iterasjon  20  L =  0.6390932991791406 \n",
      "Iterasjon  21  L =  0.6333439092229204 \n",
      "Iterasjon  22  L =  0.6272010402657282 \n",
      "Iterasjon  23  L =  0.6207383210869605 \n",
      "Iterasjon  24  L =  0.6140418825678715 \n",
      "Iterasjon  25  L =  0.6071567420955649 \n",
      "Iterasjon  26  L =  0.6000913905007801 \n",
      "Iterasjon  27  L =  0.5928675358728184 \n",
      "Iterasjon  28  L =  0.5855673864636193 \n",
      "Iterasjon  29  L =  0.5781478457278295 \n",
      "Iterasjon  30  L =  0.5707314528980622 \n",
      "Iterasjon  31  L =  0.563480132030349 \n",
      "Iterasjon  32  L =  0.5562620538209008 \n",
      "Iterasjon  33  L =  0.5491342736746104 \n",
      "Iterasjon  34  L =  0.5421278400118129 \n",
      "Iterasjon  35  L =  0.5354550846463754 \n",
      "Iterasjon  36  L =  0.529100278055234 \n",
      "Iterasjon  37  L =  0.5228859339904683 \n",
      "Iterasjon  38  L =  0.516687736724297 \n",
      "Iterasjon  39  L =  0.5105993855447888 \n",
      "Iterasjon  40  L =  0.504788038010609 \n",
      "Iterasjon  41  L =  0.4994297115291282 \n",
      "Iterasjon  42  L =  0.49449936068719014 \n",
      "Iterasjon  43  L =  0.4899677657449907 \n",
      "Iterasjon  44  L =  0.48582539905540295 \n",
      "Iterasjon  45  L =  0.48209937377897977 \n",
      "Iterasjon  46  L =  0.47879534444248356 \n",
      "Iterasjon  47  L =  0.4758307596416874 \n",
      "Iterasjon  48  L =  0.473036355836573 \n",
      "Iterasjon  49  L =  0.47029250392670435 \n",
      "Iterasjon  50  L =  0.46771311258144765 \n",
      "Iterasjon  51  L =  0.46513726989873555 \n",
      "Iterasjon  52  L =  0.46259886212242823 \n",
      "Iterasjon  53  L =  0.4600403309599749 \n",
      "Iterasjon  54  L =  0.4574098955278615 \n",
      "Iterasjon  55  L =  0.4547137757494707 \n",
      "Iterasjon  56  L =  0.4518814339411824 \n",
      "Iterasjon  57  L =  0.44883738572957765 \n",
      "Iterasjon  58  L =  0.4456654459109416 \n",
      "Iterasjon  59  L =  0.4423579553262781 \n",
      "Iterasjon  60  L =  0.4388856932819153 \n",
      "Iterasjon  61  L =  0.435298795041765 \n",
      "Iterasjon  62  L =  0.4317227195269446 \n",
      "Iterasjon  63  L =  0.42805471471494927 \n",
      "Iterasjon  64  L =  0.4241738047526634 \n",
      "Iterasjon  65  L =  0.4201275306743676 \n",
      "Iterasjon  66  L =  0.4160831708512068 \n",
      "Iterasjon  67  L =  0.41201564653181155 \n",
      "Iterasjon  68  L =  0.40795482059018895 \n",
      "Iterasjon  69  L =  0.40388700954664286 \n",
      "Iterasjon  70  L =  0.3997720345153704 \n",
      "Iterasjon  71  L =  0.3956338440645769 \n",
      "Iterasjon  72  L =  0.39165599562804726 \n",
      "Iterasjon  73  L =  0.38788185562057914 \n",
      "Iterasjon  74  L =  0.38424627719249393 \n",
      "Iterasjon  75  L =  0.3806451947944359 \n",
      "Iterasjon  76  L =  0.37703955415324814 \n",
      "Iterasjon  77  L =  0.37335159605736135 \n",
      "Iterasjon  78  L =  0.3697854164078345 \n",
      "Iterasjon  79  L =  0.3662775190117235 \n",
      "Iterasjon  80  L =  0.36295957907893694 \n",
      "Iterasjon  81  L =  0.35988599374146174 \n",
      "Iterasjon  82  L =  0.3569764923821369 \n",
      "Iterasjon  83  L =  0.3542516799757924 \n",
      "Iterasjon  84  L =  0.35164770962489644 \n",
      "Iterasjon  85  L =  0.34920485662596 \n",
      "Iterasjon  86  L =  0.34689389300335804 \n",
      "Iterasjon  87  L =  0.3446915410704649 \n",
      "Iterasjon  88  L =  0.34259509623290374 \n",
      "Iterasjon  89  L =  0.3405620780228095 \n",
      "Iterasjon  90  L =  0.3385876782645919 \n",
      "Iterasjon  91  L =  0.3367150448246832 \n",
      "Iterasjon  92  L =  0.3348580519404102 \n",
      "Iterasjon  93  L =  0.3329927204759203 \n",
      "Iterasjon  94  L =  0.3310933648962156 \n",
      "Iterasjon  95  L =  0.3292921302404529 \n",
      "Iterasjon  96  L =  0.32761236503086794 \n",
      "Iterasjon  97  L =  0.32609284233839536 \n",
      "Iterasjon  98  L =  0.3247332691168592 \n",
      "Iterasjon  99  L =  0.3235375984014873 \n",
      "Iterasjon  100  L =  0.3224505678122369 \n",
      "Iterasjon  101  L =  0.3214865947358148 \n",
      "Iterasjon  102  L =  0.3206343604645432 \n",
      "Iterasjon  103  L =  0.3198612706578793 \n",
      "Iterasjon  104  L =  0.3191668665746223 \n",
      "Iterasjon  105  L =  0.3185446540992789 \n",
      "Iterasjon  106  L =  0.3179745547349683 \n",
      "Iterasjon  107  L =  0.31745224093262825 \n",
      "Iterasjon  108  L =  0.3169930198006236 \n",
      "Iterasjon  109  L =  0.3165697578725497 \n",
      "Iterasjon  110  L =  0.3161796558495378 \n",
      "Iterasjon  111  L =  0.31583319833569645 \n",
      "Iterasjon  112  L =  0.3155067785956749 \n",
      "Iterasjon  113  L =  0.31520989965028057 \n",
      "Iterasjon  114  L =  0.3149310215321556 \n",
      "Iterasjon  115  L =  0.3146723041233728 \n",
      "Iterasjon  116  L =  0.3144355182809251 \n",
      "Iterasjon  117  L =  0.314214893736855 \n",
      "Iterasjon  118  L =  0.3140103344347991 \n",
      "Iterasjon  119  L =  0.313822479407352 \n",
      "Iterasjon  120  L =  0.3136478123362838 \n",
      "Iterasjon  121  L =  0.3134840820820714 \n",
      "Iterasjon  122  L =  0.3133342898474241 \n",
      "Iterasjon  123  L =  0.3131939346213837 \n",
      "Iterasjon  124  L =  0.3130651003187487 \n",
      "Iterasjon  125  L =  0.3129436597351624 \n",
      "Iterasjon  126  L =  0.31283049627376946 \n",
      "Iterasjon  127  L =  0.3127211617122324 \n",
      "Iterasjon  128  L =  0.31261111527948793 \n",
      "Iterasjon  129  L =  0.3124984036766995 \n",
      "Iterasjon  130  L =  0.3123931757274778 \n",
      "Iterasjon  131  L =  0.31229437705298063 \n",
      "Iterasjon  132  L =  0.31220407910297654 \n",
      "Iterasjon  133  L =  0.3121178623022366 \n",
      "Iterasjon  134  L =  0.31204021551396066 \n",
      "Iterasjon  135  L =  0.3119643235963247 \n",
      "Iterasjon  136  L =  0.3118961259445579 \n",
      "Iterasjon  137  L =  0.31183085529266463 \n",
      "Iterasjon  138  L =  0.31177099414368276 \n",
      "Iterasjon  139  L =  0.31171384403496527 \n",
      "Iterasjon  140  L =  0.31165988018478635 \n",
      "Iterasjon  141  L =  0.3116089406420555 \n",
      "Iterasjon  142  L =  0.3115597160410277 \n",
      "Iterasjon  143  L =  0.31151436513080094 \n",
      "Iterasjon  144  L =  0.3114707081849572 \n",
      "Iterasjon  145  L =  0.3114294848603564 \n",
      "Iterasjon  146  L =  0.3113891944474164 \n",
      "Iterasjon  147  L =  0.3113497852464341 \n",
      "Iterasjon  148  L =  0.311303449389997 \n",
      "Iterasjon  149  L =  0.3112308247842213 \n",
      "Iterasjon  150  L =  0.3111527536365162 \n",
      "Iterasjon  151  L =  0.3110510380101713 \n",
      "Iterasjon  152  L =  0.31091567684629673 \n",
      "Iterasjon  153  L =  0.31077570000084764 \n",
      "Iterasjon  154  L =  0.31064482984796415 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtest_Adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 15\u001b[0m, in \u001b[0;36mtest_Adam\u001b[0;34m(nn, x_data, y_data, n_iters, step_size, m)\u001b[0m\n\u001b[1;32m     13\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mforward(Z,y))\n\u001b[1;32m     14\u001b[0m     dLdZ \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLdZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     nn\u001b[38;5;241m.\u001b[39mstep_Adam(step_size)\n\u001b[1;32m     17\u001b[0m mean_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(losses)\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/neural_network.py:29\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#reversed yields the layers in reversed order\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 29\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/layers.py:360\u001b[0m, in \u001b[0;36mEmbedPosition.backward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m#Compute gradient (average over B batches) of loss wrt positional embedding w:\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw)\n\u001b[0;32m--> 360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m][:,:grad\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mb\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m#Use backwards pass of the linear layer\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed\u001b[38;5;241m.\u001b[39mbackward(grad)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2324\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2321\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[1;32m   2322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[0;32m-> 2324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2325\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = test_Adam(nn, data['x_train'], data['y_train'], 200, 0.001, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Og så kan vi plotte hvordan lossfunksjonen har endret seg gjennom iterasjonene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (100,) and (200,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterasjonnummer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogaritmen av loss-funksjon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/matplotlib/pyplot.py:2748\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2746\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2748\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2749\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2750\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1668\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1427\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1668\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/matplotlib/axes/_base.py:504\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (100,) and (200,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,100), losses)\n",
    "plt.xlabel(\"Iterasjonnummer\")\n",
    "plt.ylabel(\"Logaritmen av loss-funksjon\")\n",
    "plt.title(\"Minimering ved antall iterasjoner\")\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tester for en iterasjon for å se om den greier å predikere neste verdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 0 ,0, 1, 1]])\n",
    "X = onehot(x, m)\n",
    "\n",
    "#forward pass\n",
    "Z = nn.forward(X)\n",
    "z_hat = np.argmax(Z, axis=1)\n",
    "\n",
    "print(z_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når vi sender inn arrayet [1, 0, 0, 1, 1], vil vi ved å sende det gjennom algoritmen få predikert den første predikerte verdien som det siste elementet i det returnerte arrayet, som beskrevet i avsnitt 1.2. Siden algoritmen sorterer verdiene i arrayet bestående av 0 og 1, forventer vi at det første sifferet i det sorterte arrayet blir 0. Deretter, for å predikere resten av sekvensen, mater vi inn det siste elementet i det predikerte arrayet tilbake inn i arrayet vi sender gjennom 'forward'-steget, og fortsetter prediksjonen derfra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Videre er det nyttig med en funksjon som kan gir inn testdataen til nettverket vårt, og så en funksjon som teller antall riktige prediksjoner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediksjonsfunksjon\n",
    "def predict(nn: NeuralNetwork, xs: dict, r:int, m:int):\n",
    "    \n",
    "    batches = xs.shape[0]\n",
    "    y = np.zeros((xs.shape[0],xs.shape[1],r))\n",
    "    for i in range(batches):\n",
    "        x = xs[i]\n",
    "        for j in range(r):\n",
    "            #print(j)\n",
    "            X = onehot(x,m)\n",
    "            z = nn.forward(X)\n",
    "            Z = np.argmax(z, axis=1)\n",
    "            #print(Z.shape)\n",
    "            #print(x.shape)\n",
    "            toAppend =Z[:,-1:]\n",
    "            x = np.append(x, toAppend, axis=1)\n",
    "        y[i,:,:] = x[:,:-r]\n",
    "    return y\n",
    "\n",
    "y_pred = predict(nn, x_test, r, m)\n",
    "\n",
    "def count_correct_predictions(y_pred, y_test):\n",
    "    correct_predictions = np.count_nonzero(np.count_nonzero(y_pred == y_test, axis=2) == y_pred.shape[-1])\n",
    "    return correct_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Så kan vi se hvorvidt nettverket vårt klarer å sortere eller ikke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall rette prediksjoner: 177\n",
      "Totalt antall prediksjoner: 250\n",
      "Prosentvis riktige predikasjoner: 70.8 %\n"
     ]
    }
   ],
   "source": [
    "y_test = data['y_test']\n",
    "correct_predictions = count_correct_predictions(y_pred, y_test)\n",
    "print(\"Antall rette prediksjoner:\", correct_predictions)\n",
    "print(\"Totalt antall prediksjoner:\", y_pred.shape[1])\n",
    "print(\"Prosentvis riktige predikasjoner:\", (correct_predictions/y_pred.shape[1])*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Når to forskjellige verdier kan forekomme på fem ulike steder, resulterer dette i totalt $32$ mulige kombinasjoner ($2^5 = 32$). Denne mangfoldigheten gjør det praktisk talt umulig å teste algoritmen vår med nye sekvenser. Ideelt sett ville tapet tendert mot null, og prediksjonene ville vært korrekte hver gang, siden algoritmen burde gjenkjenne det riktige svaret ($y$) i stedet for å forutsi neste sekvens. Dette antyder at vektene våre kanskje ikke er optimalt tilpasset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definerer variabler\n",
    "r = 7\n",
    "m = 5\n",
    "n_max = 2*r-1\n",
    "\n",
    "d = 20\n",
    "k = 10\n",
    "p = 25\n",
    "L = 2\n",
    "\n",
    "embed = EmbedPosition(n_max,m,d)\n",
    "att1 = Attention(d,k)\n",
    "ff1 = FeedForward(d,p)\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "nn = NeuralNetwork([embed, att1, ff1, un_embed, softmax])\n",
    "\n",
    "data = get_train_test_sorting(r, m, samples_per_batch=250,n_batches_train=10, n_batches_test=4)\n",
    "\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "test_Adam() missing 1 required positional argument: 'm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m300\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mtest_Adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterasjonnummer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogaritmen av loss-funksjon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: test_Adam() missing 1 required positional argument: 'm'"
     ]
    }
   ],
   "source": [
    "plt.plot(np.arange(0,300), np.log(test_Adam(data['x_train'], data['y_train'], 300, 0.1,m)))\n",
    "plt.xlabel(\"Iterasjonnummer\")\n",
    "plt.ylabel(\"Logaritmen av loss-funksjon\")\n",
    "plt.title(\"Minimering ved antall iterasjoner\")\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Size of label 'j' for operand 1 (5) does not match previous terms (10).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_test \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m count_correct_predictions(y_pred, y_test)\n",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(nn, xs, r, m)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(r):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#print(j)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     X \u001b[38;5;241m=\u001b[39m onehot(x,m)\n\u001b[0;32m---> 11\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     Z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(z, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#print(Z.shape)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/neural_network.py:17\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#Recursively perform forward pass from initial input x\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 17\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/layers.py:341\u001b[0m, in \u001b[0;36mEmbedPosition.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m#We assume that n < n_max\u001b[39;00m\n\u001b[1;32m    340\u001b[0m n \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 341\u001b[0m z_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m][:,:n]\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_0\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/layers.py:251\u001b[0m, in \u001b[0;36mLinearLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m#Return output of layer\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m#y = w@x\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij,bjk->bik\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1383\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not understand the following kwargs: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m                     \u001b[38;5;241m%\u001b[39m unknown_kwargs)\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;66;03m# Build the contraction list and operand\u001b[39;00m\n\u001b[0;32m-> 1383\u001b[0m operands, contraction_list \u001b[38;5;241m=\u001b[39m \u001b[43meinsum_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43meinsum_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;66;03m# Handle order kwarg for output array, c_einsum allows mixed case\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m output_order \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum_path\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/einsumfunc.py:877\u001b[0m, in \u001b[0;36meinsum_path\u001b[0;34m(optimize, einsum_call, *operands)\u001b[0m\n\u001b[1;32m    875\u001b[0m         dimension_dict[char] \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, dimension_dict[char]):\n\u001b[0;32m--> 877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for operand \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    878\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match previous terms (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m                          \u001b[38;5;241m%\u001b[39m (char, tnum, dimension_dict[char], dim))\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     dimension_dict[char] \u001b[38;5;241m=\u001b[39m dim\n",
      "\u001b[0;31mValueError\u001b[0m: Size of label 'j' for operand 1 (5) does not match previous terms (10)."
     ]
    }
   ],
   "source": [
    "y_pred = predict(nn, x_test, r, m)\n",
    "y_test = data['y_test']\n",
    "\n",
    "correct_predictions = count_correct_predictions(y_pred, y_test)\n",
    "print(\"Antall rette prediksjoner:\", correct_predictions)\n",
    "print(\"Totalt antall prediksjoner:\", y_pred.shape[1])\n",
    "print(\"Prosentvis riktige predikasjoner:\", (correct_predictions/y_pred.shape[1])*100, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import get_train_test_addition\n",
    "#definerer variabler\n",
    "r = 6\n",
    "m = 10\n",
    "n_max = 3*r\n",
    "\n",
    "d = 30\n",
    "k = 20\n",
    "p = 40\n",
    "L = 3\n",
    "\n",
    "\n",
    "data = get_train_test_addition(2, samples_per_batch=250,n_batches_train=20, n_batches_test=4)\n",
    "\n",
    "x_train = data['x_train']\n",
    "y_train = data['y_train']\n",
    "x_test = data['x_test']\n",
    "y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Size of label 'j' for operand 1 (5) does not match previous terms (10).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m300\u001b[39m), np\u001b[38;5;241m.\u001b[39mlog(\u001b[43mtest_Adam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_train\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterasjonnummer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogaritmen av loss-funksjon\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m, in \u001b[0;36mtest_Adam\u001b[0;34m(x_data, y_data, n_iters, step_size, m)\u001b[0m\n\u001b[1;32m      8\u001b[0m y \u001b[38;5;241m=\u001b[39m y_data[i]\n\u001b[1;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m onehot(x,m)\n\u001b[0;32m---> 11\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mforward(Z,y))\n\u001b[1;32m     14\u001b[0m dLdZ \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/neural_network.py:17\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#Recursively perform forward pass from initial input x\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m---> 17\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/layers.py:341\u001b[0m, in \u001b[0;36mEmbedPosition.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m#We assume that n < n_max\u001b[39;00m\n\u001b[1;32m    340\u001b[0m n \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 341\u001b[0m z_0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWp\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m][:,:n]\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_0\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/layers.py:251\u001b[0m, in \u001b[0;36mLinearLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m#Return output of layer\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m#y = w@x\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij,bjk->bik\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1383\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not understand the following kwargs: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m                     \u001b[38;5;241m%\u001b[39m unknown_kwargs)\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;66;03m# Build the contraction list and operand\u001b[39;00m\n\u001b[0;32m-> 1383\u001b[0m operands, contraction_list \u001b[38;5;241m=\u001b[39m \u001b[43meinsum_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43meinsum_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;66;03m# Handle order kwarg for output array, c_einsum allows mixed case\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m output_order \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum_path\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/einsumfunc.py:877\u001b[0m, in \u001b[0;36meinsum_path\u001b[0;34m(optimize, einsum_call, *operands)\u001b[0m\n\u001b[1;32m    875\u001b[0m         dimension_dict[char] \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, dimension_dict[char]):\n\u001b[0;32m--> 877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for operand \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    878\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match previous terms (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m                          \u001b[38;5;241m%\u001b[39m (char, tnum, dimension_dict[char], dim))\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     dimension_dict[char] \u001b[38;5;241m=\u001b[39m dim\n",
      "\u001b[0;31mValueError\u001b[0m: Size of label 'j' for operand 1 (5) does not match previous terms (10)."
     ]
    }
   ],
   "source": [
    "plt.plot(np.arange(0,300), np.log(test_Adam(data['x_train'], data['y_train'], 300, 0.1,m)))\n",
    "plt.xlabel(\"Iterasjonnummer\")\n",
    "plt.ylabel(\"Logaritmen av loss-funksjon\")\n",
    "plt.title(\"Minimering ved antall iterasjoner\")\n",
    "plt.figure(figsize=(15,12))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
