{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tekst-generering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her vil vi forsøke å trene et nettverk som skal generere og predikere tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import onehot\n",
    "from data_generators import text_to_training_data\n",
    "from text_generation import *\n",
    "from layers import *\n",
    "from neural_network import NeuralNetwork\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 17369 characters, 50 unique.\n",
      "We will train on 3 batches of size 110\n",
      "Each sequence has length 50\n",
      "Example of a sequence (chars): \n",
      "\n",
      "Basert på våre funn kan vi konkludere med at økend\n",
      "\n",
      "Example of a sequence (idx): \n",
      "\n",
      "[10 23 40 27 39 41  1 38 47  1 43 47 39 27  1 28 42 36 36  1 33 23 36  1\n",
      " 43 31  1 33 37 36 33 34 42 26 27 39 27  1 35 27 26  1 23 41  1 49 33 27\n",
      " 36 26]\n"
     ]
    }
   ],
   "source": [
    "d = 80\n",
    "n_max = 50\n",
    "p = 100\n",
    "k = 25\n",
    "L = 2\n",
    "\n",
    "text =  open('treningsTekster/konklusjoner.txt', 'r').read()\n",
    "data,idx_to_text,text_to_idx, m = text_to_training_data(n_max,text,num_batches=3,batch_size=110)\n",
    "\n",
    "print(\"We will train on %d batches of size %d\" % (len(data['x_train']),len(data['x_train'][0])))\n",
    "print(\"Each sequence has length %d\" % n_max)\n",
    "\n",
    "print(\"Example of a sequence (chars): \\n\")\n",
    "print(''.join([idx_to_text[i] for i in data['x_train'][0][0]]))\n",
    "\n",
    "print(\"\\nExample of a sequence (idx): \\n\")\n",
    "print(data['x_train'][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi initialiserer nettverket vårt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbedPosition(n_max,m,d)\n",
    "att1 = Attention(d,k)\n",
    "att2 = Attention(d,k)\n",
    "att3 = Attention(d,k)\n",
    "att4 = Attention(d,k)\n",
    "\n",
    "\n",
    "ff1 = FeedForward(d,p)\n",
    "ff2 = FeedForward(d,p)\n",
    "ff3 = FeedForward(d,p)\n",
    "ff4 = FeedForward(d,p)\n",
    "\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "\n",
    "layers = [embed, att1, ff1, att2, ff2, att3, ff3, att4, ff4, un_embed, softmax]\n",
    "\n",
    "net = NeuralNetwork(layers)\n",
    "loss = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#henter vårt ferdigtrente\n",
    "with open(\"ferdigtrent_nn\", 'rb') as f:\n",
    "    net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29197609158509924\n",
      "0.29191859960720884\n",
      "0.2918613078656395\n",
      "0.29180582157369267\n",
      "0.29174843187394206\n",
      "0.29169066897891444\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mforward(Z,y))\n\u001b[1;32m     17\u001b[0m     dLdZ \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLdZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     net\u001b[38;5;241m.\u001b[39mstep_Adam(\u001b[38;5;241m0.000005\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mmean(losses))\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/neural_network.py:29\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#reversed yields the layers in reversed order\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 29\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[0;32m~/Documents/Fag/Vitber/TMA4320-Prosjekt-2/layers.py:126\u001b[0m, in \u001b[0;36mAttention.backward\u001b[0;34m(self, grad)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m#oppdaterer gradient for parameterene ifølge ligninger 22-25 \u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m#tar snittet av de ulike batchene\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWo\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij,bjk,bkl,bml->im\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWvw, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mb)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWv\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij,bjk,blk,bml->im\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mb\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwk\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij,bjk,bkl,bml->im\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz,g_s,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mb\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwq\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mij,bjk,blk,bml->im\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz,g_s,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mz, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m/\u001b[39mb\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/einsumfunc.py:1383\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not understand the following kwargs: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1380\u001b[0m                     \u001b[38;5;241m%\u001b[39m unknown_kwargs)\n\u001b[1;32m   1382\u001b[0m \u001b[38;5;66;03m# Build the contraction list and operand\u001b[39;00m\n\u001b[0;32m-> 1383\u001b[0m operands, contraction_list \u001b[38;5;241m=\u001b[39m \u001b[43meinsum_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43meinsum_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;66;03m# Handle order kwarg for output array, c_einsum allows mixed case\u001b[39;00m\n\u001b[1;32m   1387\u001b[0m output_order \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36meinsum_path\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/numpy/core/einsumfunc.py:876\u001b[0m, in \u001b[0;36meinsum_path\u001b[0;34m(optimize, einsum_call, *operands)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dimension_dict[char] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    875\u001b[0m         dimension_dict[char] \u001b[38;5;241m=\u001b[39m dim\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m dim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, dimension_dict[char]):\n\u001b[1;32m    877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize of label \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for operand \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    878\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match previous terms (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m                          \u001b[38;5;241m%\u001b[39m (char, tnum, dimension_dict[char], dim))\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iter = 100\n",
    "batches = 3\n",
    "\n",
    "x_data = data['x_train']\n",
    "y_data = data['y_train']\n",
    "\n",
    "\n",
    "for n in range(n_iter):\n",
    "    losses = []\n",
    "    for b in range(batches):\n",
    "        x = x_data[b]\n",
    "        y = y_data[b]\n",
    "\n",
    "        X = onehot(x,m)\n",
    "        Z = net.forward(X)\n",
    "        losses.append(loss.forward(Z,y))\n",
    "        dLdZ = loss.backward()\n",
    "        net.backward(dLdZ)\n",
    "        net.step_Adam(0.000005)\n",
    "    print(np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan også lagre nettverket med biblioteket Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"ferdigtrent\"\n",
    "\n",
    "with open(f\"{filename}_nn\", 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 37 39  1 47  1 33 37 36 33 34 42 26 27 39 27  1 38 39 37 40 32 27 33\n",
      "  41 27 41  1  1]]\n"
     ]
    }
   ],
   "source": [
    "#We can now generate text from an initial string\n",
    "start_text = \"for å konkludere prosjektet  \"\n",
    "start_idx = np.array([convertToID(start_text,text_to_idx)])\n",
    "print(start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for å konkludere prosjektet  fosormenisklan mamer.\n",
      "Reltøtere ene sultur sulår ett ensultatsen kr sperenskomar.\n",
      "Våre for diskon m sn kspludintapplikansern omern ringang væring lvære ekange onsge iljekogrmsme ne t.\n",
      "Vår Alysyse m audakfor inyster atate hvismendor.\n",
      "orne potenar dalter rongr iforknypotere rongalsn.\n",
      "Gjer vålse ar år vår har vår ar arnysertrår alysen re hv pprn ole enarser.\n",
      "Dennne potuder brudier re menratrinsmmadimmengingir kansimmen dangarnsktwolorsjoniserser hosmer ler inerssten.\n",
      "vå\n"
     ]
    }
   ],
   "source": [
    "#length of the total text sequence we want to generate\n",
    "n_gen = n_max*10\n",
    "\n",
    "generated_idx = generate(net,start_idx,m,n_max,n_gen)\n",
    "\n",
    "text = convertToTxt(generated_idx[0],idx_to_text)\n",
    "\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
